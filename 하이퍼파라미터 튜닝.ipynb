{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3yM8i6Z0bhR0"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "assert sys.version_info >= (3, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mdqv16K8bj8C"
   },
   "outputs": [],
   "source": [
    "from packaging import version\n",
    "import tensorflow as tf\n",
    "\n",
    "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v4_4ppk7bkbw",
    "outputId": "e34db9a1-f43d-4f08-e982-ae1a4ed8dc13"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# 코랩의 경우 나눔 폰트를 설치합니다.\n",
    "if 'google.colab' in sys.modules:\n",
    "    !sudo apt-get -qq -y install fonts-nanum\n",
    "    import matplotlib.font_manager as fm\n",
    "    font_files = fm.findSystemFonts(fontpaths=['/usr/share/fonts/truetype/nanum'])\n",
    "    for fpath in font_files:\n",
    "        fm.fontManager.addfont(fpath)\n",
    "\n",
    "# 나눔 폰트를 사용합니다.\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rc('font', family='NanumBarunGothic')\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RePb0bWCbsOn",
    "outputId": "6f147e4c-9455-4fd9-9098-a30478fe54c3"
   },
   "outputs": [],
   "source": [
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 77
    },
    "id": "DjOUBtkucz_p",
    "outputId": "9ad27eff-9867-4505-9115-124c165d8b39"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()  # 데이터 파일 업로드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q2Rgn5bDc-D7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"BostonHousingprice.csv\")\n",
    "X = df.iloc[:, :-1].values  # 입력 특성\n",
    "y = df.iloc[:, -1].values  # 출력 값\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0IhrQUCBbEwI",
    "outputId": "21023507-7c68-4773-a530-5d6cf8e0dd68"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv(\"BostonHousingprice.csv\")\n",
    "X = df.iloc[:, :-1].values  # 입력 특성\n",
    "y = df.iloc[:, -1].values  # 출력 값\n",
    "\n",
    "# 데이터 분리\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = np.nan_to_num(scaler.fit_transform(X_train))\n",
    "X_valid_scaled = np.nan_to_num(scaler.transform(X_valid))\n",
    "X_test_scaled = np.nan_to_num(scaler.transform(X_test))\n",
    "y_train = np.nan_to_num(y_train)\n",
    "y_valid = np.nan_to_num(y_valid)\n",
    "y_test = np.nan_to_num(y_test)\n",
    "\n",
    "# 사용자 정의 HuberLoss 함수\n",
    "class HuberLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}\n",
    "\n",
    "# 모델 구조 정의\n",
    "def build_model(hp):\n",
    "    n_hidden = hp.Int(\"n_hidden\", min_value=0, max_value=8, default=2)\n",
    "    n_neurons = hp.Int(\"n_neurons\", min_value=16, max_value=256, step=16)\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-5, max_value=1e-3, sampling=\"log\")\n",
    "    optimizer = hp.Choice(\"optimizer\", values=[\"adam\", \"sgd\"])\n",
    "\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(X_train_scaled.shape[1],)))\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    loss = HuberLoss(threshold=hp.Float(\"threshold\", min_value=0.5, max_value=5.0, step=0.5))\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=[\"mae\"])\n",
    "    return model\n",
    "\n",
    "# 이 문단부터 하이퍼 파라미터\n",
    "# Keras Tuner 설정\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective=\"val_mae\",\n",
    "    max_epochs=20,\n",
    "    factor=3,\n",
    "    directory=\"tuner_dir\",\n",
    "    project_name=\"huber_loss_tuning\",\n",
    "    max_consecutive_failed_trials=10\n",
    ")\n",
    "\n",
    "# 하이퍼파라미터 검색 실행\n",
    "tuner.search(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 최적의 하이퍼파라미터로 모델 재설정 및 훈련\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "model = build_model(best_hps)\n",
    "history = model.fit(X_train_scaled, y_train, validation_data=(X_valid_scaled, y_valid), epochs=20)\n",
    "\n",
    "# 모델 평가\n",
    "test_loss, test_mae = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "# 모델 저장\n",
    "model.save(\"final_model.keras\")\n",
    "\n",
    "# 최종 평가 결과 출력\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "print(f\"Test MAE: {test_mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "EHQ2Qw-HbM9L",
    "outputId": "8dbfb936-17f0-457b-a7e9-03b7b9a74121"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# 저장된 모델 다운로드\n",
    "files.download(\"final_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "ShvNU4cPMc1m",
    "outputId": "8e4b09fd-d491-45e6-d86a-37da29d1dedf"
   },
   "outputs": [],
   "source": [
    "results = {\"Metric\": [\"Test Loss\", \"Test MAE\"], \"Value\": [test_loss, test_mae]}\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"results.csv\", index=False)\n",
    "\n",
    "# CSV 다운로드\n",
    "files.download(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GcEpW3kPMjZG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
